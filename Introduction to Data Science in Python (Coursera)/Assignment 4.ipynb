{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Auburn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Florence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Jacksonville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Livingston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Montevallo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>River Falls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>513</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Stevens Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>514</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Waukesha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Whitewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>516</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Laramie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         State     RegionName\n",
       "0      Alabama         Auburn\n",
       "1      Alabama       Florence\n",
       "2      Alabama   Jacksonville\n",
       "3      Alabama     Livingston\n",
       "4      Alabama     Montevallo\n",
       "..         ...            ...\n",
       "512  Wisconsin    River Falls\n",
       "513  Wisconsin  Stevens Point\n",
       "514  Wisconsin       Waukesha\n",
       "515  Wisconsin     Whitewater\n",
       "516    Wyoming        Laramie\n",
       "\n",
       "[517 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_list_of_university_towns():\n",
    "#     '''Returns a DataFrame of towns and the states they are in from the \n",
    "#     university_towns.txt list. The format of the DataFrame should be:\n",
    "#     DataFrame( [ [\"Michigan\", \"Ann Arbor\"], [\"Michigan\", \"Yipsilanti\"] ], \n",
    "#     columns=[\"State\", \"RegionName\"]  )\n",
    "    \n",
    "#     The following cleaning needs to be done:\n",
    "\n",
    "#     1. For \"State\", removing characters from \"[\" to the end.\n",
    "#     2. For \"RegionName\", when applicable, removing every character from \" (\" to the end.\n",
    "#     3. Depending on how you read the data, you may need to remove newline character '\\n'. '''\n",
    "    \n",
    "#     return \"ANSWER\"\n",
    "\n",
    "def get_list_of_university_towns():\n",
    "    with open('university_towns.txt') as file:\n",
    "        data = []\n",
    "        for line in file:\n",
    "            data.append(line[:-1])\n",
    "    state_town = []\n",
    "    for line in data:\n",
    "        if line[-6:] == '[edit]':\n",
    "            state = line[:-6]\n",
    "        elif '(' in line:\n",
    "            town = line[:line.index('(')-1]\n",
    "            state_town.append([state,town])\n",
    "        else:\n",
    "            town = line\n",
    "            state_town.append([state,town])\n",
    "    state_college_df = pd.DataFrame(state_town,columns = ['State','RegionName'])\n",
    "    return state_college_df\n",
    "        \n",
    "\n",
    "get_list_of_university_towns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2008q3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_recession_start():\n",
    "#     '''Returns the year and quarter of the recession start time as a \n",
    "#     string value in a format such as 2005q3'''\n",
    "    \n",
    "#     return \"ANSWER\"\n",
    "\n",
    "\n",
    "def get_recession_start():\n",
    "    gdplev = pd.ExcelFile('gdplev.xls')\n",
    "    gdplev = gdplev.parse(\"Sheet1\", skiprows=219)\n",
    "    gdplev = gdplev[['1999q4', 9926.1]]\n",
    "    gdplev.columns = ['Quarter','GDP']\n",
    "    \n",
    "    for i in range(2, len(gdplev)):\n",
    "        if (gdplev.iloc[i-2][1] > gdplev.iloc[i-1][1]) and (gdplev.iloc[i-1][1] > gdplev.iloc[i][1]):\n",
    "            return gdplev.iloc[i-2][0]\n",
    "        \n",
    "get_recession_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009q4'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_recession_end():\n",
    "#     '''Returns the year and quarter of the recession end time as a \n",
    "#     string value in a format such as 2005q3'''\n",
    "       \n",
    "#     return \"ANSWER\"\n",
    "\n",
    "def get_recession_end():\n",
    "    gdplev = pd.ExcelFile('gdplev.xls')\n",
    "    gdplev = gdplev.parse(\"Sheet1\", skiprows=219)\n",
    "    gdplev = gdplev[['1999q4', 9926.1]]\n",
    "    gdplev.columns = ['Quarter','GDP']\n",
    "    start = get_recession_start()\n",
    "    start_index = gdplev[gdplev['Quarter'] == start].index.tolist()[0]\n",
    "    gdplev=gdplev.iloc[start_index:]\n",
    "    for i in range(2, len(gdplev)):\n",
    "        if (gdplev.iloc[i-2][1] < gdplev.iloc[i-1][1]) and (gdplev.iloc[i-1][1] < gdplev.iloc[i][1]):\n",
    "            return gdplev.iloc[i][0]\n",
    "\n",
    "get_recession_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009q2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_recession_bottom():\n",
    "#     '''Returns the year and quarter of the recession bottom time as a \n",
    "#     string value in a format such as 2005q3'''\n",
    "    \n",
    "#     return \"ANSWER\"\n",
    "\n",
    "def get_recession_bottom():\n",
    "    gdplev = pd.ExcelFile('gdplev.xls')\n",
    "    gdplev = gdplev.parse(\"Sheet1\", skiprows=219)\n",
    "    gdplev = gdplev[['1999q4', 9926.1]]\n",
    "    gdplev.columns = ['Quarter','GDP']\n",
    "    start = get_recession_start()\n",
    "    start_index = gdplev[gdplev['Quarter'] == start].index.tolist()[0]\n",
    "    end = get_recession_end()\n",
    "    end_index = gdplev[gdplev['Quarter'] == end].index.tolist()[0]\n",
    "    gdplev=gdplev.iloc[start_index:end_index+1]\n",
    "    bottom = gdplev['GDP'].min()\n",
    "    bottom_index = gdplev[gdplev['GDP'] == bottom].index.tolist()[0]-start_index\n",
    "    return gdplev.iloc[bottom_index]['Quarter']\n",
    "\n",
    "get_recession_bottom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>1996-01-31</th>\n",
       "      <th>1996-02-29</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-06-30</th>\n",
       "      <th>2019-07-31</th>\n",
       "      <th>2019-08-31</th>\n",
       "      <th>2019-09-30</th>\n",
       "      <th>2019-10-31</th>\n",
       "      <th>2019-11-30</th>\n",
       "      <th>2019-12-31</th>\n",
       "      <th>2020-01-31</th>\n",
       "      <th>2020-02-29</th>\n",
       "      <th>2020-03-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6181</td>\n",
       "      <td>0</td>\n",
       "      <td>New York</td>\n",
       "      <td>City</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York-Newark-Jersey City</td>\n",
       "      <td>Queens County</td>\n",
       "      <td>196258.0</td>\n",
       "      <td>195693.0</td>\n",
       "      <td>...</td>\n",
       "      <td>659421.0</td>\n",
       "      <td>659007.0</td>\n",
       "      <td>658239.0</td>\n",
       "      <td>656925.0</td>\n",
       "      <td>655613.0</td>\n",
       "      <td>654394.0</td>\n",
       "      <td>653930.0</td>\n",
       "      <td>653901.0</td>\n",
       "      <td>653565.0</td>\n",
       "      <td>652307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12447</td>\n",
       "      <td>1</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>City</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>185649.0</td>\n",
       "      <td>185625.0</td>\n",
       "      <td>...</td>\n",
       "      <td>712660.0</td>\n",
       "      <td>713807.0</td>\n",
       "      <td>715688.0</td>\n",
       "      <td>718245.0</td>\n",
       "      <td>721896.0</td>\n",
       "      <td>725180.0</td>\n",
       "      <td>730358.0</td>\n",
       "      <td>735910.0</td>\n",
       "      <td>744137.0</td>\n",
       "      <td>752508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>39051</td>\n",
       "      <td>2</td>\n",
       "      <td>Houston</td>\n",
       "      <td>City</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land</td>\n",
       "      <td>Harris County</td>\n",
       "      <td>93518.0</td>\n",
       "      <td>93633.0</td>\n",
       "      <td>...</td>\n",
       "      <td>186844.0</td>\n",
       "      <td>187464.0</td>\n",
       "      <td>188070.0</td>\n",
       "      <td>188496.0</td>\n",
       "      <td>189125.0</td>\n",
       "      <td>189612.0</td>\n",
       "      <td>190179.0</td>\n",
       "      <td>190395.0</td>\n",
       "      <td>190938.0</td>\n",
       "      <td>191907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>17426</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>City</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago-Naperville-Elgin</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>130920.0</td>\n",
       "      <td>130772.0</td>\n",
       "      <td>...</td>\n",
       "      <td>248372.0</td>\n",
       "      <td>248646.0</td>\n",
       "      <td>248725.0</td>\n",
       "      <td>248483.0</td>\n",
       "      <td>248278.0</td>\n",
       "      <td>248090.0</td>\n",
       "      <td>248029.0</td>\n",
       "      <td>248220.0</td>\n",
       "      <td>248599.0</td>\n",
       "      <td>249152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6915</td>\n",
       "      <td>4</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>City</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>San Antonio-New Braunfels</td>\n",
       "      <td>Bexar County</td>\n",
       "      <td>94041.0</td>\n",
       "      <td>94007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>182732.0</td>\n",
       "      <td>183350.0</td>\n",
       "      <td>183930.0</td>\n",
       "      <td>184846.0</td>\n",
       "      <td>185490.0</td>\n",
       "      <td>186244.0</td>\n",
       "      <td>186420.0</td>\n",
       "      <td>186962.0</td>\n",
       "      <td>187129.0</td>\n",
       "      <td>187718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27325</td>\n",
       "      <td>48550</td>\n",
       "      <td>29449</td>\n",
       "      <td>Winton</td>\n",
       "      <td>City</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>Duluth</td>\n",
       "      <td>Saint Louis County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>70929.0</td>\n",
       "      <td>70176.0</td>\n",
       "      <td>68979.0</td>\n",
       "      <td>68537.0</td>\n",
       "      <td>68948.0</td>\n",
       "      <td>69481.0</td>\n",
       "      <td>69423.0</td>\n",
       "      <td>69355.0</td>\n",
       "      <td>69654.0</td>\n",
       "      <td>70399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27326</td>\n",
       "      <td>51821</td>\n",
       "      <td>29449</td>\n",
       "      <td>Eastabuchie</td>\n",
       "      <td>City</td>\n",
       "      <td>MS</td>\n",
       "      <td>MS</td>\n",
       "      <td>Laurel</td>\n",
       "      <td>Jones County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>77737.0</td>\n",
       "      <td>78461.0</td>\n",
       "      <td>79138.0</td>\n",
       "      <td>79930.0</td>\n",
       "      <td>79683.0</td>\n",
       "      <td>79838.0</td>\n",
       "      <td>80272.0</td>\n",
       "      <td>80969.0</td>\n",
       "      <td>81871.0</td>\n",
       "      <td>82284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27327</td>\n",
       "      <td>232607</td>\n",
       "      <td>29449</td>\n",
       "      <td>Dean</td>\n",
       "      <td>City</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>Wichita Falls</td>\n",
       "      <td>Clay County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>178872.0</td>\n",
       "      <td>179976.0</td>\n",
       "      <td>180654.0</td>\n",
       "      <td>181188.0</td>\n",
       "      <td>181613.0</td>\n",
       "      <td>182101.0</td>\n",
       "      <td>182424.0</td>\n",
       "      <td>182764.0</td>\n",
       "      <td>182639.0</td>\n",
       "      <td>182361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27328</td>\n",
       "      <td>6638</td>\n",
       "      <td>29449</td>\n",
       "      <td>Pulaski</td>\n",
       "      <td>City</td>\n",
       "      <td>GA</td>\n",
       "      <td>GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Candler County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>97356.0</td>\n",
       "      <td>97757.0</td>\n",
       "      <td>98014.0</td>\n",
       "      <td>98225.0</td>\n",
       "      <td>98303.0</td>\n",
       "      <td>98613.0</td>\n",
       "      <td>98802.0</td>\n",
       "      <td>99227.0</td>\n",
       "      <td>99699.0</td>\n",
       "      <td>100464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27329</td>\n",
       "      <td>33089</td>\n",
       "      <td>29449</td>\n",
       "      <td>New Paris</td>\n",
       "      <td>City</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bedford County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>88745.0</td>\n",
       "      <td>89233.0</td>\n",
       "      <td>89169.0</td>\n",
       "      <td>89628.0</td>\n",
       "      <td>90073.0</td>\n",
       "      <td>90961.0</td>\n",
       "      <td>91745.0</td>\n",
       "      <td>92232.0</td>\n",
       "      <td>92787.0</td>\n",
       "      <td>93564.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27330 rows × 299 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RegionID  SizeRank   RegionName RegionType StateName State  \\\n",
       "0          6181         0     New York       City        NY    NY   \n",
       "1         12447         1  Los Angeles       City        CA    CA   \n",
       "2         39051         2      Houston       City        TX    TX   \n",
       "3         17426         3      Chicago       City        IL    IL   \n",
       "4          6915         4  San Antonio       City        TX    TX   \n",
       "...         ...       ...          ...        ...       ...   ...   \n",
       "27325     48550     29449       Winton       City        MN    MN   \n",
       "27326     51821     29449  Eastabuchie       City        MS    MS   \n",
       "27327    232607     29449         Dean       City        TX    TX   \n",
       "27328      6638     29449      Pulaski       City        GA    GA   \n",
       "27329     33089     29449    New Paris       City        PA    PA   \n",
       "\n",
       "                                  Metro          CountyName  1996-01-31  \\\n",
       "0           New York-Newark-Jersey City       Queens County    196258.0   \n",
       "1        Los Angeles-Long Beach-Anaheim  Los Angeles County    185649.0   \n",
       "2      Houston-The Woodlands-Sugar Land       Harris County     93518.0   \n",
       "3              Chicago-Naperville-Elgin         Cook County    130920.0   \n",
       "4             San Antonio-New Braunfels        Bexar County     94041.0   \n",
       "...                                 ...                 ...         ...   \n",
       "27325                            Duluth  Saint Louis County         NaN   \n",
       "27326                            Laurel        Jones County         NaN   \n",
       "27327                     Wichita Falls         Clay County         NaN   \n",
       "27328                               NaN      Candler County         NaN   \n",
       "27329                               NaN      Bedford County         NaN   \n",
       "\n",
       "       1996-02-29  ...  2019-06-30  2019-07-31  2019-08-31  2019-09-30  \\\n",
       "0        195693.0  ...    659421.0    659007.0    658239.0    656925.0   \n",
       "1        185625.0  ...    712660.0    713807.0    715688.0    718245.0   \n",
       "2         93633.0  ...    186844.0    187464.0    188070.0    188496.0   \n",
       "3        130772.0  ...    248372.0    248646.0    248725.0    248483.0   \n",
       "4         94007.0  ...    182732.0    183350.0    183930.0    184846.0   \n",
       "...           ...  ...         ...         ...         ...         ...   \n",
       "27325         NaN  ...     70929.0     70176.0     68979.0     68537.0   \n",
       "27326         NaN  ...     77737.0     78461.0     79138.0     79930.0   \n",
       "27327         NaN  ...    178872.0    179976.0    180654.0    181188.0   \n",
       "27328         NaN  ...     97356.0     97757.0     98014.0     98225.0   \n",
       "27329         NaN  ...     88745.0     89233.0     89169.0     89628.0   \n",
       "\n",
       "       2019-10-31  2019-11-30  2019-12-31  2020-01-31  2020-02-29  2020-03-31  \n",
       "0        655613.0    654394.0    653930.0    653901.0    653565.0    652307.0  \n",
       "1        721896.0    725180.0    730358.0    735910.0    744137.0    752508.0  \n",
       "2        189125.0    189612.0    190179.0    190395.0    190938.0    191907.0  \n",
       "3        248278.0    248090.0    248029.0    248220.0    248599.0    249152.0  \n",
       "4        185490.0    186244.0    186420.0    186962.0    187129.0    187718.0  \n",
       "...           ...         ...         ...         ...         ...         ...  \n",
       "27325     68948.0     69481.0     69423.0     69355.0     69654.0     70399.0  \n",
       "27326     79683.0     79838.0     80272.0     80969.0     81871.0     82284.0  \n",
       "27327    181613.0    182101.0    182424.0    182764.0    182639.0    182361.0  \n",
       "27328     98303.0     98613.0     98802.0     99227.0     99699.0    100464.0  \n",
       "27329     90073.0     90961.0     91745.0     92232.0     92787.0     93564.0  \n",
       "\n",
       "[27330 rows x 299 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def convert_housing_data_to_quarters():\n",
    "#     '''Converts the housing data to quarters and returns it as mean \n",
    "#     values in a dataframe. This dataframe should be a dataframe with\n",
    "#     columns for 2000q1 through 2016q3, and should have a multi-index\n",
    "#     in the shape of [\"State\",\"RegionName\"].\n",
    "    \n",
    "#     Note: Quarters are defined in the assignment description, they are\n",
    "#     not arbitrary three month periods.\n",
    "    \n",
    "#     The resulting dataframe should have 67 columns, and 10,730 rows.\n",
    "#     '''\n",
    "    \n",
    "#     return \"ANSWER\"\n",
    "\n",
    "\n",
    "def convert_housing_data_to_quarters():\n",
    "    import pandas as pd\n",
    "    house_df = pd.read_csv('City_Zhvi_AllHomes.csv')\n",
    "    house_df\n",
    "    \n",
    "    return house_df\n",
    "\n",
    "convert_housing_data_to_quarters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "len(right_on) must equal the number of levels in the index of \"left\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-66cfad7c6abb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdifferent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mrun_ttest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-66cfad7c6abb>\u001b[0m in \u001b[0;36mrun_ttest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# merge the housing data with university town DataFrames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_housing_data_to_quarters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniv_towns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'State'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RegionName'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'univ_town'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'univ_town'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     )\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_specification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[1;31m# note this function has side effects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_validate_specification\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1217\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                     raise ValueError(\n\u001b[1;32m-> 1219\u001b[1;33m                         \u001b[1;34m\"len(right_on) must equal the number \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1220\u001b[0m                         \u001b[1;34m'of levels in the index of \"left\"'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m                     )\n",
      "\u001b[1;31mValueError\u001b[0m: len(right_on) must equal the number of levels in the index of \"left\""
     ]
    }
   ],
   "source": [
    "# def run_ttest():\n",
    "#     '''First creates new data showing the decline or growth of housing prices\n",
    "#     between the recession start and the recession bottom. Then runs a ttest\n",
    "#     comparing the university town values to the non-university towns values, \n",
    "#     return whether the alternative hypothesis (that the two groups are the same)\n",
    "#     is true or not as well as the p-value of the confidence. \n",
    "    \n",
    "#     Return the tuple (different, p, better) where different=True if the t-test is\n",
    "#     True at a p<0.01 (we reject the null hypothesis), or different=False if \n",
    "#     otherwise (we cannot reject the null hypothesis). The variable p should\n",
    "#     be equal to the exact p value returned from scipy.stats.ttest_ind(). The\n",
    "#     value for better should be either \"university town\" or \"non-university town\"\n",
    "#     depending on which has a lower mean price ratio (which is equivilent to a\n",
    "#     reduced market loss).'''\n",
    "    \n",
    "#     return \"ANSWER\"\n",
    "\n",
    "def run_ttest():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy.stats import ttest_ind\n",
    "\n",
    "    univ_towns = get_list_of_university_towns()\n",
    "    univ_towns['univ_town'] = True\n",
    "\n",
    "    # merge the housing data with university town DataFrames\n",
    "    df = pd.merge(convert_housing_data_to_quarters(), univ_towns, how='outer', left_index=True, right_on=['State', 'RegionName'])\n",
    "    df['univ_town'] = df['univ_town'].replace({np.NaN: False})\n",
    "\n",
    "    # Get the recession quarters\n",
    "    recession_start = get_recession_start()\n",
    "    recession_bottom = get_recession_bottom()\n",
    "\n",
    "    # Parse the year and quarter of the recession quarters\n",
    "    year_recession_start = int(recession_start[0:4])\n",
    "    qtr_recession_start = int(recession_start[-1])\n",
    "    year_recession_bottom = int(recession_bottom[0:4])\n",
    "    qtr_recession_bottom = int(recession_bottom[-1])\n",
    "\n",
    "    # get the columns to keep in the merged DataFrame\n",
    "    cols_to_keep = ['State', 'RegionName', 'univ_town']\n",
    "    qtrs_to_keep = []\n",
    "    for i in range(year_recession_start, year_recession_bottom+1):\n",
    "        for j in range(1, 5):\n",
    "            if (i == year_recession_start and j < qtr_recession_start)\\\n",
    "                    or (i == year_recession_bottom and j > qtr_recession_bottom):\n",
    "                pass\n",
    "            else:\n",
    "                qtrs_to_keep.append(str(i) + 'q' + str(j))\n",
    "    df = df[cols_to_keep + qtrs_to_keep]\n",
    "\n",
    "    # Compute the price_ratio\n",
    "    df['price_ratio'] = df[recession_bottom] - df[recession_start]\n",
    "\n",
    "    # t-test to determine if there is a difference between university and non-university towns\n",
    "    univ_town_price_ratio = df[df['univ_town'] == True]['price_ratio']\n",
    "    non_univ_town_price_ratio = df[df['univ_town'] == False]['price_ratio']\n",
    "    st, p = ttest_ind(univ_town_price_ratio, non_univ_town_price_ratio, nan_policy='omit',)\n",
    "\n",
    "    # get different and better values\n",
    "    different = False\n",
    "    if p < 0.01:\n",
    "        different = True\n",
    "\n",
    "    # determine which type of town is better\n",
    "    better = \"\"\n",
    "    if univ_town_price_ratio.mean() > non_univ_town_price_ratio.mean():\n",
    "        better = \"university town\"\n",
    "    else:\n",
    "        better = \"non-university town\"\n",
    "\n",
    "    return (different, p, better)\n",
    "\n",
    "run_ttest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
